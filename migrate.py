import json
import asyncio
import os
import sys
import io
import logging
from datetime import datetime
from data_manager import get_db_pool, save_user_data, check_schema

# [Fix] ì½˜ì†” ì¶œë ¥ ì¸ì½”ë”© ì„¤ì •
if sys.stdout and hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')
elif sys.stdout and hasattr(sys.stdout, 'detach'):
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding = 'utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding = 'utf-8')
    except Exception:
        pass


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

# íŒŒì¼ ê²½ë¡œ
JSON_FILE_PATH = "user_data.json"

async def reset_database(pool):
    """ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  í…Œì´ë¸”ì„ ì‚­ì œí•˜ì—¬ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    logger.warning("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ëª¨ë“  í…Œì´ë¸”ì´ ì‚­ì œë©ë‹ˆë‹¤...")
    try:
        async with pool.acquire() as conn:
            async with conn.cursor() as cur:
                await cur.execute("SET FOREIGN_KEY_CHECKS = 0")
                await cur.execute("SHOW TABLES")
                tables = await cur.fetchall()
                for table_row in tables:
                    table_name = table_row[0]
                    logger.info(f"ğŸ—‘ï¸ í…Œì´ë¸” ì‚­ì œ ì¤‘: {table_name}")
                    await cur.execute(f"DROP TABLE IF EXISTS `{table_name}`")
                await cur.execute("SET FOREIGN_KEY_CHECKS = 1")
        logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ.")
        return True
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

async def run_migration():
    if not os.path.exists(JSON_FILE_PATH):
        logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {JSON_FILE_PATH}")
        return

    logger.info("ğŸ“‚ JSON íŒŒì¼ ë¡œë”© ì¤‘...")
    try:
        with open(JSON_FILE_PATH, "r", encoding="utf-8") as f:
            all_data = json.load(f)
    except Exception as e:
        logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return

    logger.info(f"ì´ {len(all_data)}ëª…ì˜ ìœ ì € ë°ì´í„°ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
    
    # DB í’€ ì´ˆê¸°í™”
    try:
        pool = await get_db_pool()
    except Exception as e:
        logger.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
        logger.error("config.pyì˜ ì„¤ì •(ë¹„ë°€ë²ˆí˜¸, í¬íŠ¸ ë“±)ì„ í™•ì¸í•˜ê±°ë‚˜, MySQL ì„œë²„ê°€ ì¼œì ¸ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    # ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ì…‹
    if not await reset_database(pool):
        return
        
    # ìŠ¤í‚¤ë§ˆ ì¬ìƒì„±
    logger.info("ğŸ”„ ìŠ¤í‚¤ë§ˆë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
    await check_schema(pool)
    logger.info("âœ… ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ.")

    success_count = 0
    fail_count = 0

    for user_id, user_data in all_data.items():
        try:
            # 'global_trades'ì™€ ê°™ì€ ë¹„-ìœ ì € í‚¤ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.
            if not user_id.isdigit():
                logger.warning(f"'{user_id}'ëŠ” ìœ ì € IDê°€ ì•„ë‹ˆë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            # save_user_dataê°€ ëª¨ë“  í…Œì´ë¸” ë¶„ì‚° ì €ì¥ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
            # user_data ë”•ì…”ë„ˆë¦¬ë¥¼ ê·¸ëŒ€ë¡œ ë„˜ê¹ë‹ˆë‹¤.
            await save_user_data(user_id, user_data)
            
            success_count += 1
            if success_count % 10 == 0:
                print(f"âœ… {success_count}ëª… ì²˜ë¦¬ ì™„ë£Œ...", end='\r')
                
        except Exception as e:
            fail_count += 1
            logger.error(f"\nâŒ User {user_id} ì‹¤íŒ¨: {e}")

    print(f"\n\n{'='*30}")
    print(f"ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
    print(f"ì„±ê³µ: {success_count}ëª…")
    print(f"ì‹¤íŒ¨: {fail_count}ëª…")
    print(f"{'='*30}")
    
    # ì—°ê²° ì¢…ë£Œ
    pool.close()
    await pool.wait_closed()

if __name__ == "__main__":
    try:
        asyncio.run(run_migration())
    except KeyboardInterrupt:
        print("\nì¤‘ë‹¨ë¨.")